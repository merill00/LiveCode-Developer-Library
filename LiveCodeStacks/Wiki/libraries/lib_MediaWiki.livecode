script "lib_MediaWiki"
--> MetaData
-
name: lib_MediaWiki
type: script library
version: 0.7
copyright: David Bovill
licence:  GPLv3
deps: none


/*
A library for interfacing with MediaWiki instances.
*/


--> Mediawiki
-
function mediawiki_JsonFromDroppedWikipediaURL droppedURL, wikiSlug, pApiStem
   -- a wikipedia dropped url
   --
   -- fedwiki_ParseExternalUrl droppedText
   -- put mediwiki_ExtractPageSlugFromUrl (droppedURL) into pageSlug
   
   put urldecode (wikiSlug) into pageSlug
   text_Utf8Decode pageSlug
   put wikipedia_GetApiRoot (droppedURL) into pApiStem
   
   -- this way doesn't process text properly
   put fedwiki_FetchWikipediaSummaryPageJson (pageSlug, pApiStem) into pageJSON
   
   -- this way doesn't process images and video properly
   -- put fedwikipedia_FetchPageArray (pageSlug, wikipediaURL, empty, false) into fedwikiPageArray
   -- put json_FromArray (fedwikiPageArray) into pageJSON
   
   return pageJSON
end mediawiki_JsonFromDroppedWikipediaURL

function mediawiki_ListBuiltInImages
   put "Padlock-silver.svg,Ambox_globe_content.svg,Edit-clear.svg,Wiki_letter_w_cropped.svg" into mediaWikiImageList
   return mediaWikiImageList
end mediawiki_ListBuiltInImages

command mediawiki_FetchSectionQueryInfo pageSlug, sectionNum, @sectionDescription, @pageTitle, @shortImageFile, @sectionArray, @wikipediaRevisionID
   put sandbox_FetchSectionArray (pageSlug, sectionNum) into sandboxArray
   sandbox_DeconstructSectionArray sandboxArray, pageTitle, sectionDescription, imageArray, sectionArray, wikipediaRevisionID
   put mediawiki_ExtractFirstInterestingImage (imageArray) into shortImageFile
   return sandboxArray
end mediawiki_FetchSectionQueryInfo

function mediawiki_FetchSummaryDescription pageSlug, pFetchHow
   switch pFetchHow
      case "parse"
         mediawiki_FetchPageParseInfo pageSlug, pageDescription, pageTitle, shortImageFile, infoBoxArray, 0
         break
      default -- "query"
         mediawiki_FetchPageQueryInfo pageSlug, pageDescription, pageTitle, shortImageFile, lastRevisionID
   end switch
   return pageDescription
end mediawiki_FetchSummaryDescription

command mediawiki_FetchPageQueryInfo pageSlug, @pageDescription, @pageTitle, @shortImageFile, @lastRevisionID, pApiStem
   put sandbox_ConstructPageQueryFragment (pageSlug, "wiki", true) into sandBoxFragment
   -- mediawiki_TestSandboxFragment sandBoxFragment
   put mediawiki_GetSandboxArray (sandBoxFragment, pApiStem) into sandboxArray
   sandbox_DeconstructPageArray sandboxArray, pageTitle, pageDescription, shortImageFile, lastRevisionID
   put the result into sandboxPageArray
   return sandboxPageArray
end mediawiki_FetchPageQueryInfo

command mediawiki_FetchPageParseInfo pageSlug, @pageDescription, @pageTitle, @shortImageFile, @infoBoxArray, pSectionNum, pApiStem
   -- Uses "parse" to extract wiktext sections. Lot's of fiddling with text. Messy as it returns lots of page templates that need cleaning. But we get wiki links
   
   if pSectionNum is empty then
      put sandbox_ConstructSectionFragment (pageSlug) into sandBoxFragment
   else
      put sandbox_ConstructSectionFragment (pageSlug, pSectionNum) into sandBoxFragment
   end if
   
   put mediawiki_GetSandboxArray (sandBoxFragment, pApiStem) into sandboxArray
   put sandboxArray ["parse"] into pageArray
   put pageArray ["title"] into pageTitle
   put pageArray ["wikitext"]["*"] into pageDescription
   mediawiki_CleanPageDescription pageDescription, infoBoxArray
   if infoBoxArray is an array then
      put infoBoxArray ["image"] into shortImageFile
   else
      put pageArray ["images"] into imageArray
      put mediawiki_ExtractFirstInterestingImage (imageArray) into shortImageFile
   end if
   return sandboxArray
end mediawiki_FetchPageParseInfo

command mediawiki_CleanPageDescription @pageDescription, @infoBoxArray
   put mediawikia_ExtractInfobox (pageDescription) into infoBox
   put mediawiki_ConvertInfoBox (infoBox) into infoBoxArray
   fedwikipedia_CleanLine pageDescription
end mediawiki_CleanPageDescription


--> Mediawiki | Template | Infobox
-
function mediawiki_ConvertInfoBox infobox
   delete char 1 to 2 of infoBox
   delete char -2 to -1 of infoBox
   put word 1 to -1 of infoBox into infoBox
   if word 1 of infoBox is not "InfoBox" then return empty
   
   put word 2 to -1 of line 1 of infoBox into infoBoxName
   delete line 1 of infoBox
   
   set the itemdelimiter to "="
   repeat for each line someLine in infoBox
      if char 1 of word 1 of someLine is not "|" then
         next repeat
      end if
      
      put item 1 of someLine into someKey
      delete char 1 of someKey
      put word 1 of someKey into someKey
      
      put item 2 to -1 of of someLine into someValue
      put word 1 to -1 of someValue into someValue
      
      put someValue into infoBoxArray [someKey]
   end repeat
   return infoBoxArray
end mediawiki_ConvertInfoBox

function mediawikia_ExtractInfobox wikiText
   put mediawikia_ExtractTemplate ("Infobox", wikiText) into foundTemplate
   return foundTemplate
end mediawikia_ExtractInfobox


--> Mediawiki | Template
-
function mediawikia_ExtractTemplate templateName, wikiText
   local startWikiTemplate, endWikiTemplate
   mediawiki_SetTemplateOffsets templateName, wikiText, startWikiTemplate, testEndNum
   put the result into foundTemplate
   return word 1 to -1 of foundTemplate
end mediawikia_ExtractTemplate

command mediawiki_SetTemplateOffsets templateName, wikiText, @startWikiTemplate, @testEndNum
   -- {{Infobox
   put "[^\}]+" into untilCurlyBracket
   put "(\{\{" & templateName & untilCurlyBracket & "\}\})" into someReg
   put "(?m)" before someReg -- multiline search
   
   repeat
      if matchchunk (wikiText, someReg, startWikiTemplate, endWikiTemplate) is true then
         put startWikiTemplate into testStartNum
         put endWikiTemplate into testEndNum
         repeat
            put _letsFindNestedStartBracketNum (testStartNum, testEndNum, wikiText) into foundNum
            if foundNum = 0 then
               exit repeat
            else
               --  let's go get stuff till the end of foundNum closing brackets
               put _lastNestedBracket (wikiText, foundNum, testEndNum) into newTestEndNum
               put testEndNum into testStartNum
               put newTestEndNum into testEndNum
            end if
         end repeat
         
         put testEndNum into endWikiTemplate
         put char startWikiTemplate to endWikiTemplate of wikiText into foundTemplate
         return foundTemplate
      else
         put 0 into startWikiTemplate
         put 0 into endWikiTemplate
         return empty
      end if
   end repeat
end mediawiki_SetTemplateOffsets

private function _letsFindNestedStartBracketNum startWikiTemplate, endWikiTemplate, wikiText
   put char (startWikiTemplate+2) to (endWikiTemplate-2) of wikiText into testBit
   put 0 into lastOffset
   put 0 into foundNum
   repeat
      put offset ("{{", testBit, lastOffset) into newOffset
      if newOffset = 0 then exit repeat
      add 1 to foundNum
      add newOffset to lastOffset
   end repeat
   return foundNum
end _letsFindNestedStartBracketNum

private function _lastNestedBracket wikiText, foundNum, endWikiTemplate
   repeat foundNum
      put offset ("}}", wikiText, endWikiTemplate) into nextOffset
      if nextOffset = 0 then
         -- "err, should be an ending template bracket"
         return 0
      else
         add (nextOffset + 2) to endWikiTemplate 
      end if
   end repeat 
   return endWikiTemplate
end _lastNestedBracket

function wikipedia_ConstructUrl pageTitle, pSectionTitle
   replace "-" with space in pageTitle
   put text_InitialCaps (pageTitle) into pageSlug
   replace space with "_" in pageSlug
   put "https://en.wikipedia.org/wiki/" & pageSlug into wikipediaUrl
   if pSectionTitle is not empty then
      replace space with "_" in pSectionTitle
      put "#" & pSectionTitle after wikipediaUrl
   end if
   return wikipediaUrl
end wikipedia_ConstructUrl

command mediawiki_DeconstructImageWikiText imageWikiText, @shortImageFile, @captionBit
   delete char 1 to 2 of imageWikiText
   delete char -2 to -1 of imageWikiText
   
   set the itemdelimiter to "|"
   put item 1 of imageWikiText into shortFileBit
   put item 2 of imageWikiText into thumbBit
   put item 3 of imageWikiText into directionBit
   put item -1 of imageWikiText into captionBit
   
   set the itemdelimiter to ":"
   put item 2 of shortFileBit into shortImageFile
   replace space with "_" in shortImageFile
   
   return shortFileBit & CR & thumbBit & CR & directionBit
end mediawiki_DeconstructImageWikiText

command mediawiki_ConvertSectionTitle @sectionTitle
   put word 1 to -1 of sectionTitle into sectionTitle
   repeat while char -1 of sectionTitle = "="
      add 1 to headerLevel
      delete char -1 of sectionTitle
   end repeat
   
   delete char 1 to headerLevel of sectionTitle
   put word 1 to -1 of sectionTitle into sectionTitle
   put space before sectionTitle -- optional
   repeat (headerLevel-1)
      put "#" before sectionTitle
   end repeat
end mediawiki_ConvertSectionTitle

function mediwiki_ExtractAndDeleteFirstSection @wikiText
   put offset (CR & CR & "==", wikiText) into charNum
   if charNum = 0 then return empty
   
   put char 1 to charNum of wikiText into firstSection
   add 1 to charNum
   delete char 1 to charNum of wikiText
   return firstSection
end mediwiki_ExtractAndDeleteFirstSection

command mediawiki_DeleteFirstSection @wikiText
   put offset (CR & CR & "==", wikiText) into charNum
   if charNum = 0 then return false
   
   add 1 to charNum
   delete char 1 to charNum of wikiText
   return true
end mediawiki_DeleteFirstSection

function mediwiki_ExtractPageTitleFromUrl someUrl
   -- compatibility stub
   return mediwiki_ExtractPageSlugFromUrl (someUrl)
end mediwiki_ExtractPageTitleFromUrl

function mediwiki_ExtractPageSlugFromUrl someUrl
   -- was mediwiki_ExtractPageSlugFromUrl
   -- https://en.wikipedia.org/wiki/Cat#/media/File:AfricanWildCat.jpg
   -- url_Deconstruct someUrl, someProtocol, urlDomain, urlPath, shortName, fileExtension, uName, pWord
   set the itemdelimiter to "/"
   put item 3 of someUrl into urlDomain
   if urlDomain ends with ".wikipedia.org" is false then return empty
   put item 4 of someUrl into urlPath
   if urlPath is not "wiki" then return empty
   put item 5 of someUrl into shortName
   
   put urldecode (shortName) into pageSlug
   text_Utf8Decode pageSlug
   return pageSlug
end mediwiki_ExtractPageSlugFromUrl


--> Wikipedia | Sandbox
-
function mediawiki_GetSandboxArray sandBoxFragment, pApiStem
   put mediawiki_GetSandboxJSON (sandBoxFragment, pApiStem) into someJSON
   put json_ToArray (someJSON) into someArray
   return someArray 
end mediawiki_GetSandboxArray

function mediawiki_GetSandboxJSON sandBoxFragment, pApiStem
   put mediawiki_ConstructSandboxURL (sandBoxFragment, pApiStem) into restURL
   put mediawiki_GetRestJSON (restURL) into someJSON
   return someJSON
end mediawiki_GetSandboxJSON

function mediawiki_GetRestArray restURL
   put mediawiki_GetRestJSON (restURL) into someJSON
   put json_ToArray (someJSON) into someArray
   return someArray
end mediawiki_GetRestArray

function mediawiki_GetRestJSON restURL
   wikipedia_SetUserAgent
   set the httpheaders to "Accept: application/json"
   put url restURL into someJSON
   return someJSON
end mediawiki_GetRestJSON

function mediawiki_ConstructSandboxURL sandBoxFragment, pApiStem
   if pApiStem is empty then put "http://en.wikipedia.org/w/api.php" into pApiStem
   set the itemdelimiter to "?"
   delete item 1 of sandBoxFragment
   put pApiStem & "?" & sandBoxFragment into restURL
   return restURL
end mediawiki_ConstructSandboxURL


--> WikiPedia
-
function wikipedia_ExtractSummary someTitles, pApiRoot, pFormat
   -- same as "wikipedia_FetchPageExtract"
   -- does not work for old mediawikis
   -- /w/api.php?action=query&prop=extracts&format=json&exintro=&explaintext=&exsectionformat=wiki&titles=North%20Africa&uselang=de
   if pFormat is empty then put "json" into pFormat
   
   put wikipedia_GetApiRoot (pApiRoot) & "?action=query&prop=extracts&exintro=&titles=" into apiStem
   put apiStem & urlEncode(someTitles) into someURL
   put "&format=" & pFormat after someURL
   put url someURL into someValue
   return someValue
end wikipedia_ExtractSummary

function wikipedia_FetchPageExtract pageTitle, pApiStem
   put mediawiki_FetchPageBits (pageTitle, "extracts", "exintro=true", pApiStem) into someJSON
   return someJSON
end wikipedia_FetchPageExtract

function wikipedia_FetchPageStuff pageTitle, pApiStem
   put mediawiki_FetchPageBits (pageTitle, "extracts|links|extlinks|categories|images|pageimages|pageterms", "exintro=true", pApiStem) into someJSON
   return someJSON
end wikipedia_FetchPageStuff

function wikipedia_ExtractInfo someTitles
   if pFormat is empty then put "json" into pFormat
   
   -- prop=info for basic page info 
   put wikipedia_GetApiRoot() & "?action=query&prop=info&titles=" into apiStem
   
   put apiStem & urlEncode(someTitles) into someURL
   put "&format=" & pFormat after someURL
   put url someURL into someValue
   return someValue
end wikipedia_ExtractInfo


--> MediaWiki
-
function mediawiki_FetchPageBits pageTitle, pProps, pOtherBits, pApiStem, pFormat
   if pProps is empty then put "revisions" into pProps
   if pFormat is empty then put "json" into pFormat
   if pApiStem is empty then put wikipedia_GetApiRoot() into pApiStem -- wikpedia
   
   put urlencode(pageTitle) into pageTitle
   put merge("[[pApiStem]]?action=query&prop=[[pProps]]&titles=[[pageTitle]]&format=[[pFormat]]") into someURL
   if pOtherBits is not empty then put "&" &  pOtherBits after someURL
   put url someUrl into someResult
   return someResult
end mediawiki_FetchPageBits

function mediawiki_FetchWikiText pageTitle, pApiStem
   -- need to add error checking
   put mediawiki_FetchPage (pageTitle, "revisions", "content", empty, pApiStem) into someJSON
   put json_ToArray (someJSON) into someArray
   put someArray ["query"]["pages"] into pageArray
   put line 1 of keys (pageArray) into pageID
   put pageArray [pageID]["revisions"]["1"]["*"] into wikiText
   return wikiText
end mediawiki_FetchWikiText

function mediawiki_FetchPage pageTitle, pProps, pReturnChunks, pOtherBits, pApiStem, pFormat
   /*
   api.php ? action=query & prop=revisions & rvprop=content & titles=ArticleA|ArticleB
   
   api.php ? action=query & prop=revisions & revids=12345 
   & rvprop=timestamp & rvlimit=10 & rvdir=older
   -- &prop=revisions&titles=Agents&rvstartid=1689&rvprop=timestamp|user|comment|content&format=xml"
   
   https://en.wikipedia.org/w/api.php?action=query&titles=Main%20Page&prop=revisions&rvprop=content&format=json
   */
   if pProps is empty then put "revisions" into pProps
   if pReturnChunks is empty then put "content" into pReturnChunks
   if pFormat is empty then put "json" into pFormat
   if pApiStem is empty then put wikipedia_GetApiRoot() into pApiStem -- wikpedia
   
   put urlencode(pageTitle) into pageTitle
   put merge("[[pApiStem]]?action=query&prop=[[pProps]]&titles=[[pageTitle]]&rvprop=[[pReturnChunks]]&format=[[pFormat]]") into someURL
   -- put merge("[[pApiStem]]?action=query&prop=[[pProps]]&titles=[[pageTitle]]&format=[[pFormat]]") into someURL
   if pOtherBits is not empty then put "&" &  pOtherBits after someURL
   put url someUrl into someResult
   return someResult
end mediawiki_FetchPage


--> WikiMedia | Utilities
-
/*
You can find useful help and examples here - https://commons.wikimedia.org/wiki/Commons:API/MediaWiki
*/

function wikimedia_FetchFilesInCategory someCategory, pFormat
   -- api.php?action=query&list=categorymembers&cmtype=file&cmtitle=Category:CC-BY-2.0
   if pFormat is empty then put "json" into pFormat
   
   get merge ("?action=query&list=categorymembers&cmtype=file&cmtitle=Category:[[someCategory]]&format=[[pFormat]]")
   put wikimedia_GetApiRoot() & it into someUrl
   
   wikipedia_SetUserAgent
   put url someURL into someJSON
   return someJSON
end wikimedia_FetchFilesInCategory

function wikimedia_FetchFileCategories shortImageFile
   -- put wikimedia_FetchCommonsCategories ("Commons-logo.svg")
   put wikimedia_RestfulFetch (shortImageFile, "categories") into someJSON
   return someJSON
end wikimedia_FetchFileCategories

function wikimedia_FetchNearbyFiles someLat, someLong, pRadius, pFormat
   /*
   -- action=query&generator=geosearch&ggsprimary=all&ggsnamespace=6&ggsradius=500
   -- &ggscoord=51.5|11.95&prop=imageinfo&iiprop=url&iiurlwidth=200
   
   put wikimedia_FetchNearbyFiles ( " 51.5", "11.95")
   */
   
   if pFormat is empty then put "json" into pFormat
   if pRadius is empty then put 500 into pRadius
   
   get merge ("?action=query&generator=geosearch&ggsprimary=all&ggsnamespace=6&ggsradius=[[pRadius]]&format=[[pFormat]]")
   
   put wikimedia_GetApiRoot() & it into someUrl
   put "&ggscoord=" & someLat & "|" & someLong after someUrl -- 51.5|11.95
   put "&prop=imageinfo&iiprop=url&iiurlwidth=200" after someUrl
   
   wikipedia_SetUserAgent
   put url someURL into someJSON
   return someJSON
end wikimedia_FetchNearbyFiles

function wikimedia_RestfulFetch shortImageFile, pProps, pExtraProps, pFormat
   if pFormat is empty then put "json" into pFormat
   get merge ("?action=query&titles=Image:[[shortImageFile]]&prop=[[pProps]]&format=[[pFormat]]")
   if pExtraProps is not empty then put "&" & pExtraProps after it
   put wikimedia_GetApiRoot() & it into someURL
   
   wikipedia_SetUserAgent
   put url someURL into someJSON
   if the number of words of someJSON = 0 then
      return someURL
   else
      return someJSON
   end if
end wikimedia_RestfulFetch


--> Wikipedia | Stems
-
function wikipedia_GetApiRoot wikipediaURL
   if wikipediaURL is empty then
      return "https://en.wikipedia.org/w/api.php"
   else
      -- https://de.wikipedia.org/wiki/Jo_Fabian
      set the itemdelimiter to "/"
      put item 1 to 3 of wikipediaURL into apiRoot
      put "/w/api.php" after apiRoot
      return apiRoot
   end if
end wikipedia_GetApiRoot

function wikimedia_GetApiRoot
   return "https://commons.wikimedia.org/w/api.php"
end wikimedia_GetApiRoot

command wikipedia_SetUserAgent
   -- https://www.mediawiki.org/wiki/API:Main_page#Identifying_your_client
   put "User-Agent: WikiApp/0.1 (http://livecode.viral.academy/wikiapp.html; david@viral.academy) MacOS Livecode/7.06" into userHeader
   set the httpheaders to userHeader
end wikipedia_SetUserAgent


--> Deps
-
function utf8_Encode someText
   put unidecode(uniencode(someText),"UTF8") into encodedText
   return encodedText
end utf8_Encode

command text_Utf8Decode @utf8Text
   put unidecode(uniencode(utf8Text,"UTF8")) into utf8Text
   -- put uniencode(utf8Text,"UTF8") into someU16
   -- put unidecode(someU16, "ANSI") into utf8Text
end text_Utf8Decode

function json_ToArray pJSON
   if pJSON is empty then return false
   try -- as otherwise an error with non-json causes script to exit
      local tArray,tKeys
      if pJSON is empty then return empty
      repeat for each line tKey in mergJSONDecode(pJSON,"tArray")
         put json_ToArray(tArray[tKey]) into tArray[tKey]
      end repeat
      return tArray
   catch e
      return empty
   end try
end json_ToArray

command url_Deconstruct someUrl, @someProtocol, @urlDomain, @urlPath, @shortName, @fileExtension, @uName, @pWord
   /*
   -- from http://regexlib.com/REDetails.aspx?regexp_id=628
   -- put "(?:(?<protocol>http(?:s?)|ftp)(?:\:\/\/)) (?:(?<usrpwd>\w+\:\w+)(?:\@))? (?<domain>[^/\r\n\:]+)? (?<port>\:\d+)? (?<path>(?:\/.*)*\/)? (?<filename>.*?\.(?<ext>\w{2,4}))? (?<qrystr>\??(?:\w+\=[^\#]+)(?:\&?\w+\=\w+)*)* (?<bkmrk>\#.*)?" into someReg
   */
   
   set the itemdelimiter to ":"
   put item 1 of someUrl into someProtocol
   if someProtocol is among the items of "file:binFile:ftp:http:https" then
      put someUrl into someFile
      delete item 1 of someFile
      if char 1 to 2 of someFile = "//" then delete char 1 to 2 of someFile
      
      -- just in case it has a ? param at the end
      -- strip it for now
      set the itemdelimiter to "?"
      put item 1 of someFile into someFile
      set the itemdelimiter to ":"
      
      get offset("@", someFile)
      if it = 0 then
         put empty into uName
         put empty into pWord
      else
         put char 1 to (it - 1) of someFile into authBit
         repeat while char 1 of authBit is "/"
            delete char 1 of authBit
         end repeat
         if the number of items of authBit = 2 then
            put item 1 of authBit into uName
            put item 2 of authBit into pWord
            delete char 1 to it of someFile
         else
            -- "@" must be in url ignore
            put empty into uName
            put empty into pWord
         end if
      end if
      file_Deconstruct someFile, someRoot, shortName, fileExtension
      
      set the itemdelimiter to "/"
      put item 1 of someRoot into UrlDomain
      put item 2 to -1 of someRoot into urlPath
      return true
   else
      put empty into someProtocol
      put empty into UrlDomain
      put empty into urlPath
      put empty into shortName
      put empty into fileExtension
      put empty into uName
      put empty into pWord
      return false
   end if
end url_Deconstruct

command file_Deconstruct someFile, @someRoot, @shortName, @fileExtension
   -- was "deconstruct_File"
   -- should turn someRoot into someFolder and add "/" to end
   
   if someFile is empty then
      put the effective filename of this stack into someFile
   end if
   put someFile into someRoot
   put the itemdelimiter into originalDelim
   
   set the itemdelimiter to "/"
   put last item of someFile into shortName
   delete last item of someRoot
   
   if shortName contains "." then
      set the itemdelimiter to "."
      put last item of shortName into fileExtension
      delete last item of shortName
   else
      put empty into fileExtension
   end if
   set the itemdelimiter to originalDelim
end file_Deconstruct

function text_InitialCaps someText
   repeat with wordNum = 1 to the number of words of someText
      put tolower(word wordNum of someText) into someWord
      put toupper(char 1 of someWord ) into char 1 of someWord
      put someWord into word wordNum of someText
   end repeat
   return someText
end text_InitialCaps
